1.

Fonction scrape_page :
Prend une URL en entrée.
Envoie une requête à l'URL et analyse le contenu HTML à l'aide de BeautifulSoup.
Extrait le texte de la citation et les balises de chaque citation de la page.
Renvoie une liste de dictionnaires, chacun contenant le texte et les balises d'une citation.

URL :
Une liste d'URL pour les 5 premières pages du site Web de citation.

Balises souhaitées :
Un ensemble contenant les balises à filtrer par : "love", "inspirational", "life" et "humor".

Raclage et filtrage :
Parcourt la liste des URL, en scrappant chaque page.
Filtre les guillemets pour ne conserver que ceux contenant au moins une des balises souhaitées.

DataFrame et CSV :
Crée un Pandas DataFrame à partir des citations filtrées.
Écrit le DataFrame dans un fichier CSV nommé results.csv.


2.

Se connecter au site et récupérer le token:
Code : login_and_get_token fonction.
Description: Utilise une session pour se connecter au site en envoyant une requête POST avec les informations de connexion. Récupère le token de la réponse et retourne la session et le token.
Sortie: Le token est écrit dans results.csv.

Scraper les deux premières pages de citations avec le tag 'books':
Code : scrape_tagged_quotes fonction.
Description: Envoie des requêtes GET pour récupérer les pages contenant des citations avec le tag books. Extrait les citations et leurs tags de la réponse HTML.
Sortie: Les citations sont stockées dans une liste book_quotes.

Filtrer les doublons et ajouter les citations au fichier results.csv:
Code: filter_duplicates function et écriture dans le fichier CSV.
Description: Filtre les citations en éliminant les doublons basés sur le texte de la citation. Ajoute les citations uniques au fichier results.csv.
Sortie: Les citations uniques sont ajoutées à results.csv.
